{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-lX2LNl-bZ6"
      },
      "source": [
        "# AnÃ¡lisis de RetenciÃ³n de Clientes (CHURN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBpI7IH--c0c"
      },
      "source": [
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF2frQQR-iK9"
      },
      "source": [
        "## Contexto del Negocio\n",
        "\n",
        "El banco ficticio Monopoly, con aÃ±os de operaciÃ³n en Chile, ha sido recientemente adquirido por una entidad extranjera: el banco Dormammu.\n",
        "\n",
        "Como parte del proceso de integraciÃ³n, Dormammu ha solicitado un anÃ¡lisis exhaustivo de la base de datos de clientes de Monopoly â€”que contiene 574 variables y 51.124 registrosâ€” con el objetivo de:\n",
        "\n",
        "* Comprender el comportamiento financiero de los clientes actuales.\n",
        "* Identificar patrones de uso en productos como cuentas corrientes y tarjetas de crÃ©dito.\n",
        "* Detectar oportunidades para mejorar los servicios existentes y aumentar la rentabilidad.\n",
        "* Evaluar estrategias para retener clientes actuales y atraer nuevos usuarios hacia los productos del banco fusionado.\n",
        "\n",
        "Este anÃ¡lisis serÃ¡ clave para diseÃ±ar polÃ­ticas comerciales, campaÃ±as de fidelizaciÃ³n, y planes de producto mÃ¡s alineados con los perfiles y necesidades detectadas en la base de clientes.\n",
        "\n",
        "**Objetivo del AnÃ¡lisis**:\n",
        "\n",
        "**RetenciÃ³n de Clientes**: Desarrollar un modelo predictivo que permita identificar clientes con riesgo de abandonar el banco. El objetivo es facilitar la creaciÃ³n de campaÃ±as de retenciÃ³n proactivas y focalizadas, basadas en patrones de comportamiento reales.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55nFrsv0-jzB"
      },
      "outputs": [],
      "source": [
        "#importaciones de librerÃ­as\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "import joblib\n",
        "from seaborn import load_dataset\n",
        "from seaborn import kdeplot\n",
        "from seaborn import lmplot\n",
        "from seaborn import boxplot\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from scipy.sparse import hstack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConfiguraciÃ³n del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skRDGggIcNT_",
        "outputId": "ab9ce46b-55b4-413e-fbf5-15d8c388ecef"
      },
      "outputs": [],
      "source": [
        "# Descargar dataset\n",
        "path = kagglehub.dataset_download(\"nadiaarellanog/base-clientes-monopoly\")\n",
        "\n",
        "print(\"Ruta:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48eTrBvLcUtD",
        "outputId": "8f64f2f0-6167-453f-83f8-6ee1d1653786"
      },
      "outputs": [],
      "source": [
        "monopoly = pd.read_csv(path + \"/Base_clientes_Monopoly.csv\", delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csT3yh6e-k-Z",
        "outputId": "7ad0cff1-3237-4794-9241-62cfcaae1be5"
      },
      "outputs": [],
      "source": [
        "# Mostrar las primeras filas del DataFrame para verificar la carga del archivo\n",
        "print(monopoly.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjoeTPXS-pJW"
      },
      "source": [
        "### ComprensiÃ³n de los Datos\n",
        "\n",
        "El conjunto de datos proporcionado por el banco Monopoly (ahora parte de Dormammu) contiene informaciÃ³n detallada de mÃ¡s de 51.000 clientes y 574 variables, abarcando:\n",
        "\n",
        "* Datos demogrÃ¡ficos\n",
        "* InformaciÃ³n sobre productos financieros (cuentas, tarjetas, crÃ©ditos)\n",
        "* Actividad transaccional mensual (volumen y frecuencia)\n",
        "* Indicadores de comportamiento y engagement\n",
        "\n",
        "Este dataset permitirÃ¡ construir una visiÃ³n rica y detallada de cada cliente, asÃ­ como modelar su propensiÃ³n a continuar utilizando los servicios del banco.\n",
        "\n",
        "\n",
        "### Objetivos de esta Fase\n",
        "\n",
        "Durante la comprensiÃ³n de los datos se busca:\n",
        "\n",
        "* Entender la estructura y significado de las variables disponibles, incluyendo unidades, escalas y formatos.\n",
        "* Detectar problemas de calidad de datos: valores faltantes, formatos inconsistentes, tipos incorrectos o valores atÃ­picos.\n",
        "* Identificar variables relevantes para el modelo de retenciÃ³n, basÃ¡ndose en su naturaleza, correlaciÃ³n con el target y distribuciÃ³n.\n",
        "\n",
        "\n",
        "### DescripciÃ³n de Variables Relevantes\n",
        "\n",
        "A continuaciÃ³n se resumen algunas de las variables clave agrupadas por tipo, destacando su utilidad en el anÃ¡lisis:\n",
        "\n",
        "ðŸ”¹ Variables DemogrÃ¡ficas\n",
        "* RegiÃ³n: Zona geogrÃ¡fica de residencia del cliente. Ãštil para segmentaciÃ³n geogrÃ¡fica.\n",
        "* Edad: Factor clave en el comportamiento financiero y tipo de productos utilizados.\n",
        "* Sexo: Potencialmente relevante para personalizaciÃ³n de estrategias.\n",
        "* Renta: Indicador del poder adquisitivo del cliente, relacionado con su volumen de uso de productos.\n",
        "\n",
        "ðŸ”¹ Productos Financieros\n",
        "* Ctacte: Tenencia de cuenta corriente. Asociada a clientes activos.\n",
        "* Hipotecario: Presencia de crÃ©dito hipotecario. Generalmente asociado a mayor compromiso con el banco.\n",
        "* Debito / TC: Indican si el cliente posee tarjetas de dÃ©bito o crÃ©dito, respectivamente.\n",
        "\n",
        "ðŸ”¹ Actividad Transaccional\n",
        "* Txs_T12: NÃºmero de transacciones en tarjetas de crÃ©dito durante el mes mÃ¡s reciente.\n",
        "* CUPO_L1 / L2 / MX: LÃ­mites de crÃ©dito en compras nacionales, avances y compras internacionales.\n",
        "* FlgAct_T12: Indicador de actividad reciente en tarjeta de crÃ©dito.\n",
        "\n",
        "\n",
        "### Problemas Detectados en el AnÃ¡lisis Inicial\n",
        "\n",
        "Durante la exploraciÃ³n preliminar se identificaron los siguientes desafÃ­os:\n",
        "\n",
        "* Valores nulos en variables clave como Renta, RegiÃ³n y Sexo.\n",
        "* Tipos inconsistentes: Algunas variables numÃ©ricas aparecen como tipo object por uso de comas en lugar de puntos decimales o sÃ­mbolos extraÃ±os.\n",
        "* Outliers: En variables como Txs_T12 y FacAN_T12 se observan valores atÃ­picos que podrÃ­an afectar el entrenamiento del modelo.\n",
        "\n",
        "Estos problemas se abordarÃ¡n en la etapa de preparaciÃ³n de los datos, mediante imputaciÃ³n, conversiÃ³n de tipos y tratamiento de valores extremos segÃºn sea necesario.\n",
        "\n",
        "\n",
        "### Exploraciones Iniciales Realizadas\n",
        "\n",
        "Se realizaron algunas visualizaciones para comprender mejor la distribuciÃ³n de los datos:\n",
        "\n",
        "* Subsegmentos de Clientes: Permite observar agrupaciones internas segÃºn nivel de productos, ingresos u otros factores.\n",
        "* DistribuciÃ³n Regional: Ofrece perspectiva sobre la presencia geogrÃ¡fica de los clientes.\n",
        "* GÃ©nero: Ayuda a identificar sesgos o necesidades de segmentaciÃ³n.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se carga el conjunto de datos original monopoly y se convierte en un DataFrame de Pandas para facilitar su manipulaciÃ³n y anÃ¡lisis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Q6CRZool-rLU"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(monopoly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNaIaDt4-sJ6"
      },
      "source": [
        "Esta conversiÃ³n permite trabajar con una estructura tabular estÃ¡ndar en Python, ideal para aplicar operaciones de limpieza, transformaciÃ³n y exploraciÃ³n utilizando herramientas del ecosistema cientÃ­fico como pandas, numpy y scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzmcNKG9-tdm",
        "outputId": "bfcf660c-192b-4792-c0e5-52ce62a5a74a"
      },
      "outputs": [],
      "source": [
        "#Cantidad de filas(registros) x cantidad de columnas(variables)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN1B1eDE-vkH"
      },
      "source": [
        "Este comando muestra las dimensiones del DataFrame, es decir:\n",
        "\n",
        "* **Filas** (registros): 51,124 clientes\n",
        "* **Columnas** (variables): 574 caracterÃ­sticas asociadas a cada cliente\n",
        "\n",
        "Esta informaciÃ³n es clave para dimensionar el volumen de datos con el que se trabajarÃ¡ durante las etapas de anÃ¡lisis y modelado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "iEJpuwcS-0rm",
        "outputId": "85abc02d-30c5-4616-d4cd-9ec707aed1c6"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "cuzyHcuG-5jc",
        "outputId": "f18b749d-9734-45eb-dbab-65fb76aa58f8"
      },
      "outputs": [],
      "source": [
        "# Registro aleatorio\n",
        "df.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "ep1FyzFp-6qq",
        "outputId": "8634ffd5-6732-41e4-9f07-268763e5cd8a"
      },
      "outputs": [],
      "source": [
        "# Genera el grÃ¡fico de barras\n",
        "plt.figure(figsize=(12, 6))\n",
        "conteo_subsegmento = df['Subsegmento'].value_counts()\n",
        "ax = conteo_subsegmento.plot.bar(rot=45, color='orange', width=0.8)\n",
        "\n",
        "# Etiquetas de texto para cada barra\n",
        "for i, v in enumerate(conteo_subsegmento):\n",
        "    ax.text(i, v + 5, str(v), ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel(\"Subsegmento\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.title(\"DistribuciÃ³n de Subsegmento\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhZOG7WU-8RD"
      },
      "source": [
        "El grÃ¡fico de barras muestra que el subsegmento \"170\" es el mÃ¡s frecuente en la base de datos, lo que indica que esta categorÃ­a domina en esta variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ylo-4nj0_Bn9",
        "outputId": "af623645-b177-45e2-b51c-53fbca8532d5"
      },
      "outputs": [],
      "source": [
        "# Genera el grÃ¡fico de barras\n",
        "plt.figure(figsize=(17, 6))\n",
        "conteo_region = df['Region'].value_counts()\n",
        "ax = conteo_region.plot.bar(rot=0, color='purple', width=0.4)\n",
        "\n",
        "# Etiquetas de texto para cada barra\n",
        "for i, v in enumerate(conteo_region):\n",
        "    ax.text(i, v + 5, str(v), ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.title(\"DistribuciÃ³n de RegiÃ³n\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8mFp6z4_DDl"
      },
      "source": [
        "La variable `Region` presenta una fuerte concentraciÃ³n en la categorÃ­a 13, lo que coincide con su moda. No obstante, se observan inconsistencias en el formato de algunas regiones, como `7` y `7.0`, que representan el mismo valor pero en diferentes tipos. Estas inconsistencias serÃ¡n tratadas en la fase de limpieza de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "O-nM9LUQ_Ecn",
        "outputId": "5ff3168d-9047-4780-900a-4c9ef34db518"
      },
      "outputs": [],
      "source": [
        "# Genera el grÃ¡fico de barras\n",
        "plt.figure(figsize=(17, 6))\n",
        "conteo_sexo = df['Sexo'].value_counts()\n",
        "ax = conteo_sexo.plot.bar(rot=0, color='green', width=0.4)\n",
        "\n",
        "# Etiquetas de texto para cada barra\n",
        "for i, v in enumerate(conteo_sexo):\n",
        "    ax.text(i, v + 5, str(v), ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel(\"Sexo\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.title(\"DistribuciÃ³n de GÃ©nero: Hombres vs. Mujeres\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MClznn1k_GFB"
      },
      "source": [
        "El grÃ¡fico de barras muestra que la categorÃ­a masculina es la mÃ¡s representada en el conjunto de datos, indicando una mayor proporciÃ³n de hombres que mujeres en la muestra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "PjIANmxa_LYB",
        "outputId": "82f76600-d39f-4bf3-aeb4-fa71f89cd722"
      },
      "outputs": [],
      "source": [
        "# Eliminar valores nulos de la columna que se va a graficar\n",
        "data_to_plot = df['Txs_T12'].dropna()\n",
        "\n",
        "# Crear el histograma\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.hist(data_to_plot, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "\n",
        "# AÃ±adir tÃ­tulo y etiquetas\n",
        "plt.title('Histograma de Transacciones (Txs_T12)', fontsize=16)\n",
        "plt.xlabel('Valor de Transacciones', fontsize=14)\n",
        "plt.ylabel('Frecuencia', fontsize=14)\n",
        "\n",
        "# AÃ±adir lÃ­neas de referencia\n",
        "mean_value = data_to_plot.mean()\n",
        "plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=1, label=f'Media: {mean_value:.2f}')\n",
        "\n",
        "# AÃ±adir leyenda\n",
        "plt.legend()\n",
        "\n",
        "# AÃ±adir cuadrÃ­cula\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "\n",
        "# Mostrar el histograma\n",
        "plt.tight_layout()  # Ajustar para que todo se muestre correctamente\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI0cFHDRAaFI"
      },
      "source": [
        "El histograma muestra la distribuciÃ³n del nÃºmero de transacciones mensuales en tarjeta de crÃ©dito (`Txs_T12`). Se observa una alta concentraciÃ³n de clientes con pocos movimientos, lo que indica un uso limitado del producto por la mayorÃ­a de la base.\n",
        "\n",
        "Una lÃ­nea discontinua roja representa la media (**~2.59 transacciones**), visiblemente desplazada hacia la derecha de la mayorÃ­a de los datos, lo que evidencia un sesgo fuerte hacia valores bajos.\n",
        "\n",
        "**Observaciones clave**\n",
        "\n",
        "* **DistribuciÃ³n sesgada**: La variable presenta una distribuciÃ³n fuertemente sesgada a la derecha (right-skewed), con la mayorÃ­a de los valores cercanos a cero.\n",
        "* **Media baja**: Aunque el promedio se sitÃºa en 2.59, este valor estÃ¡ influido por unos pocos clientes con volÃºmenes transaccionales altos.\n",
        "* **Baja actividad general**: La gran mayorÃ­a de los clientes realiza pocas transacciones mensuales, lo que puede implicar baja utilizaciÃ³n del producto o inactividad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "WokBbR2WAq26",
        "outputId": "d3e8abf0-c730-4e4f-8fae-b2b742a435f1"
      },
      "outputs": [],
      "source": [
        "# Filtrar valores nulos en la columna Txs_T12\n",
        "data_to_plot = df['Txs_T12'].dropna()\n",
        "\n",
        "# Crear el diagrama de caja (boxplot)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(data_to_plot, vert=False, patch_artist=True,\n",
        "            boxprops=dict(facecolor='lightblue'), whis=10)  # Valor whis ajustado\n",
        "\n",
        "# AÃ±adir tÃ­tulo y etiquetas de los ejes\n",
        "plt.title('Diagrama de Caja de Transacciones (Txs_T12)', fontsize=16)\n",
        "plt.xlabel('Valor de Transacciones', fontsize=14)\n",
        "\n",
        "# Agregar la curva de densidad (KDE plot) con transparencia\n",
        "sns.kdeplot(data_to_plot, color='blue', bw_adjust=0.5, alpha=0.5)  # Ajuste de suavizado y transparencia\n",
        "\n",
        "# Mostrar el diagrama de caja y configurar la cuadrÃ­cula\n",
        "plt.grid(axis='x', alpha=0.75)\n",
        "plt.tight_layout()  # Asegurar que todos los elementos se muestren correctamente\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaD7hJaLBAl3"
      },
      "source": [
        "El grÃ¡fico combina un diagrama de caja con una curva de densidad (KDE) para representar la distribuciÃ³n de transacciones mensuales (`Txs_T12`). Ambos elementos revelan una alta concentraciÃ³n de valores cercanos a cero, con una caÃ­da abrupta a medida que aumentan.\n",
        "\n",
        "El diagrama de caja muestra una dispersiÃ³n estrecha en el rango bajo, con outliers significativos en el extremo derecho, lo que indica la presencia de clientes con actividad inusualmente alta. Los bigotes se extienden hasta aproximadamente 50 transacciones, mientras que el KDE evidencia un fuerte sesgo a la derecha, con un Ãºnico pico dominante.\n",
        "\n",
        "**Observaciones clave**\n",
        "\n",
        "* **Alta concentraciÃ³n en valores bajos**: La mayorÃ­a de los clientes realiza muy pocas transacciones mensuales.\n",
        "* **Outliers relevantes**: Existen casos aislados con volÃºmenes considerablemente mÃ¡s altos que el promedio, lo cual influye en la media.\n",
        "* **DistribuciÃ³n asimÃ©trica**: La forma de la curva y el diagrama de caja evidencian una distribuciÃ³n fuertemente sesgada (right-skewed), algo tÃ­pico en datos financieros de uso de productos.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOKYnBFnBZ8D"
      },
      "source": [
        "## PreparaciÃ³n de los Datos\n",
        "\n",
        "En esta fase, se limpia y transforma el dataset para asegurar que sea consistente, completo y adecuado para el modelado. Dado que se detectaron valores nulos, tipos inconsistentes y outliers, se aplicarÃ¡n transformaciones especÃ­ficas para garantizar la calidad de los datos.\n",
        "\n",
        "\n",
        "### Objetivos de esta Etapa\n",
        "Los principales objetivos de esta fase incluyen:\n",
        "\n",
        "A. **Limpieza de Nulos**: Identificar y tratar valores nulos, tipos incorrectos y registros anÃ³malos.\n",
        "\n",
        "B. **ConversiÃ³n y TransformaciÃ³n**: Asegurar que las variables estÃ©n correctamente tipadas y representadas.\n",
        "\n",
        "C. **Tratamiento de Outliers**: Limpiar los valores extremos detectados.\n",
        "\n",
        "D. **NormalizaciÃ³n/EstandarizaciÃ³n**: Escalar variables financieras para asegurar comparabilidad en el modelado.\n",
        "\n",
        "### A. Limpieza de Nulos\n",
        "1. **Variables demogrÃ¡ficas**: Sexo y RegiÃ³n contienen valores faltantes. Dado su potencial valor analÃ­tico, se imputarÃ¡n utilizando la moda o el valor mÃ¡s frecuente dentro de subgrupos.\n",
        "2. **Variable financiera â€“ Renta**: Dado su impacto en el comportamiento del cliente, se imputarÃ¡ usando la mediana por subsegmento, para preservar relaciones contextuales.\n",
        "3. Se incluirÃ¡ un heatmap de nulos y un grÃ¡fico de barras para identificar las columnas mÃ¡s afectadas.\n",
        "\n",
        "### B. ConversiÃ³n y TransformaciÃ³n\n",
        "1. Variables mal tipadas como object (ej. Renta, CUPO_L1, etc.) serÃ¡n convertidas a float, eliminando sÃ­mbolos o formatos invÃ¡lidos.\n",
        "2. RegiÃ³n serÃ¡ convertida a tipo categÃ³rico, ya que representa una ubicaciÃ³n y no una magnitud continua.\n",
        "\n",
        "### C. Tratamiento de Outliers\n",
        "Se identificaron valores extremos en variables como Txs_T12 y FacAN_T12. Para ello:\n",
        "\n",
        "1. Se usarÃ¡n boxplots y curvas KDE para detectar y visualizar estas anomalÃ­as.\n",
        "2. El tratamiento aplicarÃ¡ reglas basadas en el rango intercuartÃ­lico (IQR) o transformaciones logarÃ­tmicas, segÃºn el impacto observado.\n",
        "\n",
        "### D. NormalizaciÃ³n y EstandarizaciÃ³n\n",
        "1. EstandarizaciÃ³n (z-score) se aplicarÃ¡ a variables financieras como Renta, CUPO_L1, CUPO_L2 y CUPO_MX.\n",
        "2. NormalizaciÃ³n se considerarÃ¡ para variables transaccionales si presentan asimetrÃ­a fuerte.\n",
        "\n",
        "Estas tÃ©cnicas aseguran que las variables contribuyan equitativamente en los modelos, sin que su escala domine el aprendizaje.\n",
        "\n",
        "### PreparaciÃ³n del Target para el Modelado\n",
        "El target serÃ¡ la suma anual de transacciones con tarjetas (Txs_T01 a Txs_T12), una mÃ©trica que representa la actividad del cliente durante un aÃ±o.\n",
        "\n",
        "Pasos:\n",
        "1. **CÃ¡lculo**: Se sumarÃ¡n las columnas mensuales para crear total_transacciones_anual.\n",
        "2. **TransformaciÃ³n**: Dado el sesgo hacia valores bajos, se aplicarÃ¡ una transformaciÃ³n logarÃ­tmica (log1p) para mejorar la distribuciÃ³n y el ajuste en modelos de regresiÃ³n.\n",
        "\n",
        "### Resultado Final\n",
        "Esta etapa deja el dataset limpio, tipado correctamente y escalado, listo para aplicar modelos de regresiÃ³n o clasificaciÃ³n. La calidad de esta preparaciÃ³n es clave para generar modelos robustos y relevantes para las necesidades estratÃ©gicas del banco Dormammu.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qD7q2jTwHYI3"
      },
      "outputs": [],
      "source": [
        "# Selecciona todas las columnas mensuales de transacciones\n",
        "transacciones_mensuales = [f'Txs_T{i:02}' for i in range(1, 13)]\n",
        "\n",
        "# Verifica que las columnas existan en el DataFrame\n",
        "transacciones_mensuales = [col for col in transacciones_mensuales if col in df.columns]\n",
        "\n",
        "# Calcula el total anual de transacciones\n",
        "df['total_transacciones_anual'] = df[transacciones_mensuales].sum(axis=1)\n",
        "target_regresion = df['total_transacciones_anual']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUDq8n2wBbdZ",
        "outputId": "c320d7e5-0302-43c2-b604-9fd23a796c87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Id  Subsegmento   Sexo   Region     Edad     Renta  Antiguedad  Internauta  Adicional  Dualidad  Monoproducto   Ctacte  Consumo  Hipotecario   Debito  CambioPin  Cuentas       TC  CUPO_L1  CUPO_L2  CUPO_MX\n",
            "count   51124.0      51124.0  51123  51071.0  51124.0   37759.0     51124.0     51124.0    51124.0   51124.0       51124.0  51124.0  51124.0      51124.0  51124.0    31736.0  51124.0  51124.0  51124.0  51124.0  51124.0\n",
            "unique      NaN          NaN      2      NaN      NaN   34276.0         NaN         NaN        NaN       NaN           NaN      NaN      NaN          NaN      NaN        NaN      NaN      NaN      NaN   4591.0   3522.0\n",
            "top         NaN          NaN      H      NaN      NaN  400000.0         NaN         NaN        NaN       NaN           NaN      NaN      NaN          NaN      NaN        NaN      NaN      NaN      NaN      1.0   1000.0\n",
            "freq        NaN          NaN  27410      NaN      NaN     205.0         NaN         NaN        NaN       NaN           NaN      NaN      NaN          NaN      NaN        NaN      NaN      NaN      NaN   5516.0   5058.0\n"
          ]
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# AnÃ¡lisis clientes\n",
        "# Utiliza describe() para obtener estadÃ­sticas de variables categÃ³ricas y numÃ©ricas\n",
        "df_describe = df.iloc[:, 0:21].describe(include='all')\n",
        "\n",
        "# Filtra solo las columnas count, unique, top, freq\n",
        "df_filtered = df_describe.loc[['count', 'unique', 'top', 'freq']]\n",
        "\n",
        "# Muestra solo las estadÃ­sticas seleccionadas\n",
        "print(df_filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy0x9FZfCX--"
      },
      "source": [
        "Se inspeccionaron las estadÃ­sticas bÃ¡sicas de un subconjunto de variables utilizando df.describe(include='all'). A continuaciÃ³n se destacan observaciones clave por tipo de variable:\n",
        "\n",
        "ðŸ”¹ Identificadores y CategÃ³ricas\n",
        "* **Id**: Completo (51.124 valores), actÃºa como identificador Ãºnico.\n",
        "* **Subsegmento**: Completo, pero no se muestran mÃ©tricas adicionales al tratarse de una variable categÃ³rica numÃ©rica.\n",
        "* **Sexo**: Casi completa (1 valor nulo). Dos categorÃ­as, con predominio masculino (H, ~27.410 casos).\n",
        "* **RegiÃ³n**: Presenta valores faltantes (~53 ausentes). DeberÃ¡ convertirse a categÃ³rica y limpiarse por formato inconsistente (ej. \"7\" vs \"7.0\").\n",
        "\n",
        "ðŸ”¹ Variables NumÃ©ricas\n",
        "* **Edad, AntigÃ¼edad**: Completas y numÃ©ricas continuas, sin issues aparentes.\n",
        "* **Renta**: Incompleta (~26% nulos). Altamente variable (34.276 valores Ãºnicos). El valor mÃ¡s frecuente es 400.000 (205 registros), lo que podrÃ­a reflejar un default artificial o segmento comÃºn.\n",
        "\n",
        "ðŸ”¹ Variables Indicadoras (Binarias)\n",
        "* Variables como **Internauta, Adicional, Dualidad, Monoproducto, Ctacte, Consumo, Hipotecario, Debito** estÃ¡n completas y parecen binarias (0/1). Su anÃ¡lisis de frecuencias serÃ¡ Ãºtil para evaluar activaciÃ³n o tenencia de productos.\n",
        "\n",
        "ðŸ”¹ Variables con Alta Ausencia\n",
        "* **CambioPin**: ~38% de valores nulos. Requiere decisiÃ³n sobre imputaciÃ³n o eliminaciÃ³n, segÃºn su relevancia en el modelo.\n",
        "\n",
        "ðŸ”¹ LÃ­mites de CrÃ©dito\n",
        "* **CUPO_L1 / L2 / MX**: Completos, con alta cardinalidad. Valores frecuentes como 1000.0 o 1.0 podrÃ­an corresponder a cupos mÃ­nimos estandarizados o defaults del sistema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Msl8EfQ6Bogh",
        "outputId": "82492834-b7d6-4630-90a3-e39b223bacce"
      },
      "outputs": [],
      "source": [
        "#AnÃ¡lisis de movimientos durante el mes de Diciembre\n",
        "df.iloc[::, list(range(21, 67)) + [573]].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "t6yoHc-LB6vr"
      },
      "outputs": [],
      "source": [
        "# Crea una copia del DataFrame para no modificar el original en las siguientes ejecuciones\n",
        "df_copia = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vb2Z4BcDQYj",
        "outputId": "89457676-a08a-43d9-f733-b478b79b2638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Id                int64\n",
            "Subsegmento       int64\n",
            "Sexo             object\n",
            "Region          float64\n",
            "Edad              int64\n",
            "Renta            object\n",
            "Antiguedad        int64\n",
            "Internauta        int64\n",
            "Adicional         int64\n",
            "Dualidad          int64\n",
            "Monoproducto      int64\n",
            "Ctacte            int64\n",
            "Consumo           int64\n",
            "Hipotecario       int64\n",
            "Debito            int64\n",
            "CambioPin       float64\n",
            "Cuentas           int64\n",
            "TC                int64\n",
            "CUPO_L1           int64\n",
            "CUPO_L2          object\n",
            "CUPO_MX          object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Mostrar la media\n",
        "print(df.iloc[:, 0:21].dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbO0mHA1DcgY"
      },
      "source": [
        "Se inspeccionaron los tipos de las primeras columnas del dataset para identificar inconsistencias relevantes:\n",
        "\n",
        "* **CategÃ³ricas mal tipadas**: Variables como Renta, CUPO_L2, CUPO_MX estÃ¡n en formato object, lo que sugiere problemas de formato (p. ej., uso de comas decimales o sÃ­mbolos no numÃ©ricos). Se transformarÃ¡n a float tras limpieza.\n",
        "* **Variables binarias**: Columnas como Internauta, Ctacte, Hipotecario, entre otras, estÃ¡n correctamente como int, aunque podrÃ­an representarse como bool para mejorar la semÃ¡ntica.\n",
        "* **RegiÃ³n**: EstÃ¡ en formato float64, pero representa una categorÃ­a geogrÃ¡fica. SerÃ¡ convertida a tipo category para reflejar su naturaleza.\n",
        "\n",
        "Este diagnÃ³stico guiarÃ¡ la conversiÃ³n y estandarizaciÃ³n de tipos durante la limpieza.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHtzUJQeDxkG",
        "outputId": "9c240cdc-5c8f-4941-f838-8b6c26e19c0a"
      },
      "outputs": [],
      "source": [
        "# Seleccionar solo las columnas numÃ©ricas\n",
        "df_numerico = df.iloc[:, 0:21].select_dtypes(include=[np.number])\n",
        "\n",
        "# Calcular la mediana de las columnas numÃ©ricas\n",
        "mediana = df_numerico.median()\n",
        "\n",
        "# Mostrar la mediana\n",
        "print(mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2EpAAFREXZR",
        "outputId": "1693fc4c-7931-463f-9d42-daf0db62c172"
      },
      "outputs": [],
      "source": [
        "subset_df = df.iloc[:, :21]\n",
        "moda_result = subset_df.mode()\n",
        "print(moda_result.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJnyBRG3Eg1i"
      },
      "source": [
        "Se analizaron las medianas y modas de las variables clave para identificar tendencias centrales en el comportamiento y perfil de los clientes:\n",
        "\n",
        "ðŸ”¹Perfil DemogrÃ¡fico y General\n",
        "* **Edad**: Mediana de 35 aÃ±os, con moda en 27 â†’ clientela relativamente joven.\n",
        "* **AntigÃ¼edad**: Mediana de 25 meses, moda de 10 meses â†’ predominan clientes nuevos.\n",
        "* **RegiÃ³n**: Moda en 13.0, lo que indica alta concentraciÃ³n geogrÃ¡fica en esa zona (probablemente Santiago).\n",
        "* **Sexo**: Moda â€œHâ€ â†’ mayorÃ­a de los clientes son hombres.\n",
        "\n",
        "ðŸ”¹Productos y Servicios\n",
        "* **Internauta, DÃ©bito, Ctacte, CambioPin**: Moda de 1, lo que sugiere alto uso de servicios digitales y productos bÃ¡sicos.\n",
        "* **CrÃ©ditos (Consumo, Hipotecario), Adicionales, Dualidad**: Moda de 0 â†’ baja adopciÃ³n de productos avanzados.\n",
        "\n",
        "ðŸ”¹Ingresos y Cupos\n",
        "* **Renta**:\n",
        "  * Mediana no mostrada por estar incompleta (~26% de nulos).\n",
        "  * Moda en 400.000 â†’ posible valor comÃºn o default.\n",
        "* **CUPO_L1**: Mediana en 800.000, moda en 200.000 â†’ lÃ­mites estandarizados.\n",
        "* **CUPO_MX**: Moda en 1.000, indicando cupos internacionales bajos.\n",
        "\n",
        "ðŸ”¹Tarjetas de CrÃ©dito\n",
        "* **TC (nÃºmero de tarjetas)**: Mediana de 2, moda de 1 â†’ mayorÃ­a con una sola tarjeta, pero con una fracciÃ³n relevante que posee mÃ¡s.\n",
        "\n",
        "ðŸ”¹ConclusiÃ³n\n",
        "\n",
        "El banco mantiene una base joven, mayoritariamente masculina y reciente, con acceso preferente a productos digitales y bÃ¡sicos. La baja adopciÃ³n de productos financieros complejos sugiere oportunidades en venta cruzada (cross-sell) o estrategias de fidelizaciÃ³n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lwfI19RwE-Fd",
        "outputId": "074e70ad-9eb3-4136-dc86-1db5aec22344"
      },
      "outputs": [],
      "source": [
        "df_copia.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcLwJfVeFJvB"
      },
      "source": [
        "Se identificaron valores nulos en un subconjunto de variables:\n",
        "\n",
        "| Variable | Nulos | Comentario                                                               |\n",
        "| -------- | ----- | ------------------------------------------------------------------------ |\n",
        "| Sexo     | 1     | Valor faltante puntual, puede imputarse con la moda                      |\n",
        "| Region   | 53    | Faltantes mÃ¡s relevantes; requiere anÃ¡lisis antes de imputar o eliminar. |\n",
        "| Otras    | 0     | Completas                                                                |\n",
        "\n",
        "ðŸ”¹Observaciones clave:\n",
        "* La mayorÃ­a de las columnas crÃ­ticas estÃ¡n completas.\n",
        "* Las columnas con nulos tienen baja proporciÃ³n sobre el total (51.124 registros), por lo que imputar con valores dominantes o eliminar esos pocos registros no tendrÃ­a impacto significativo.\n",
        "* En etapas posteriores se definirÃ¡ si se imputan (Region, Sexo) o si se excluyen, segÃºn su relevancia en el modelado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdUQZcX5P9g6",
        "outputId": "dd2d9852-ec0e-475a-c2f1-c07246f98ca6"
      },
      "outputs": [],
      "source": [
        "# ConversiÃ³n de Renta a numÃ©rico\n",
        "df_copia['Renta'] = pd.to_numeric(df['Renta'], errors='coerce')\n",
        "\n",
        "# Imputaciones\n",
        "df_copia['Sexo'] = df_copia['Sexo'].fillna(df['Sexo'].mode()[0])\n",
        "df_copia['Region'] = df_copia['Region'].fillna(df['Region'].mode()[0])\n",
        "df_copia['Renta'] = df_copia.groupby('Subsegmento')['Renta'].transform(lambda x: x.fillna(x.median()))\n",
        "df_copia['CambioPin'] = df_copia['CambioPin'].fillna(df['CambioPin'].median())\n",
        "\n",
        "# Nota: Aunque actualmente no hay nulos en 'Renta' ni 'CambioPin',\n",
        "# estas imputaciones estÃ¡n incluidas como medida preventiva para garantizar\n",
        "# estabilidad si se aplicara el pipeline a nuevos datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZSyASLqQj0g"
      },
      "source": [
        "Este bloque de cÃ³digo ejecuta la limpieza e imputaciÃ³n de datos faltantes en el DataFrame df_copia, con el objetivo de garantizar que las columnas crÃ­ticas estÃ©n completas y correctamente tipadas. Esta etapa es esencial para evitar errores en etapas posteriores del anÃ¡lisis y asegurar la integridad del pipeline de modelado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T4vXRt5QBWQ",
        "outputId": "7528e0b7-6cf1-4a18-bfe3-3de8ffc52f99"
      },
      "outputs": [],
      "source": [
        "# Convertir variables numÃ©ricas que estÃ¡n en formato object a float\n",
        "# Primero, eliminar caracteres especiales que impidan la conversiÃ³n\n",
        "\n",
        "# Remover posibles sÃ­mbolos de moneda y convertir a numÃ©rico\n",
        "df_copia['Renta'] = pd.to_numeric(df['Renta'], errors='coerce')\n",
        "df_copia['CUPO_L1'] = pd.to_numeric(df['CUPO_L1'], errors='coerce')\n",
        "df_copia['CUPO_L2'] = pd.to_numeric(df['CUPO_L2'], errors='coerce')\n",
        "df_copia['CUPO_MX'] = pd.to_numeric(df['CUPO_MX'], errors='coerce')\n",
        "\n",
        "# Verificar la conversiÃ³n\n",
        "print(df[['Renta', 'CUPO_L1', 'CUPO_L2', 'CUPO_MX']].dtypes)\n",
        "\n",
        "# Convertir `Region` a tipo categÃ³rico\n",
        "df_copia['Region'] = df_copia['Region'].astype('category')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4Dp6HdYYQCXK"
      },
      "outputs": [],
      "source": [
        "# FunciÃ³n para filtrar outliers utilizando el rango intercuartÃ­lico (IQR)\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df_copia[column].quantile(0.25)\n",
        "    Q3 = df_copia[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    # Filtra los datos fuera del rango IQR\n",
        "    filtered_df = df_copia[(df_copia[column] >= Q1 - 1.5 * IQR) & (df_copia[column] <= Q3 + 1.5 * IQR)]\n",
        "    return filtered_df\n",
        "\n",
        "# Aplicar la funciÃ³n en algunas de las variables financieras clave\n",
        "df_copia = remove_outliers(df_copia, 'Renta')\n",
        "df_copia = remove_outliers(df_copia, 'CUPO_L1')\n",
        "df_copia = remove_outliers(df_copia, 'CUPO_L2')\n",
        "df_copia = remove_outliers(df_copia, 'CUPO_MX')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO1NH22QQDWd",
        "outputId": "620e15b6-8679-40a4-f938-a44f5345aa79"
      },
      "outputs": [],
      "source": [
        "# EstandarizaciÃ³n de variables financieras clave (para modelos de regresiÃ³n lineal o logÃ­stica)\n",
        "scaler = StandardScaler()\n",
        "df_copia[['Renta', 'CUPO_L1', 'CUPO_L2', 'CUPO_MX']] = scaler.fit_transform(df_copia[['Renta', 'CUPO_L1', 'CUPO_L2', 'CUPO_MX']])\n",
        "\n",
        "# NormalizaciÃ³n de las variables de transacciones (para modelos como K-Means)\n",
        "transacciones_mensuales = [f'Txs_T{i:02}' for i in range(1, 13)]\n",
        "scaler = MinMaxScaler()\n",
        "df_copia[transacciones_mensuales] = scaler.fit_transform(df_copia[transacciones_mensuales])\n",
        "\n",
        "# Revisar los resultados de la normalizaciÃ³n y estandarizaciÃ³n\n",
        "print(df_copia[['Renta', 'CUPO_L1', 'CUPO_L2', 'CUPO_MX']].describe())\n",
        "print(df_copia[transacciones_mensuales].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "ARQTRAhlNYf-",
        "outputId": "70d9bdc1-e32a-4247-84a1-0ed5f71ffa22"
      },
      "outputs": [],
      "source": [
        "# Verificar el tipo de dato del target\n",
        "print(\"Tipo de dato del target:\", df_copia['total_transacciones_anual'].dtype)\n",
        "\n",
        "# Visualizar la distribuciÃ³n del target con un histograma y un grÃ¡fico de densidad\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Histograma\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df_copia['total_transacciones_anual'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('DistribuciÃ³n del Target (Histograma)')\n",
        "plt.xlabel('Total de Transacciones Anual')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "# GrÃ¡fico de Densidad (KDE)\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(df_copia['total_transacciones_anual'].dropna(), color='blue')\n",
        "plt.title('DistribuciÃ³n del Target (Densidad)')\n",
        "plt.xlabel('Total de Transacciones Anual')\n",
        "plt.ylabel('Densidad')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HvWfABMNtly"
      },
      "source": [
        "ðŸ”¹AnÃ¡lisis del Target\n",
        "* **Tipo de Dato**:\n",
        "  * El target, correspondiente al total anual de transacciones por cliente, estÃ¡ en formato float64. Este tipo de dato es adecuado para modelado de regresiÃ³n, ya que representa una variable numÃ©rica continua.\n",
        "* **DistribuciÃ³n del Target â€“ Histograma**:\n",
        "  * La mayorÃ­a de los clientes concentra sus transacciones anuales en valores bajos, prÃ³ximos a cero.\n",
        "  * La distribuciÃ³n presenta un sesgo positivo (cola a la derecha), con una frecuencia decreciente a medida que aumentan las transacciones. Pocos clientes superan las 100 transacciones anuales.\n",
        "* **DistribuciÃ³n del Target â€“ Curva de Densidad (KDE)**:\n",
        "  * El KDE reafirma la concentraciÃ³n en valores bajos, con un pico marcado en la zona inicial de la escala y una larga cola hacia la derecha.\n",
        "  * Este patrÃ³n sugiere una fuerte asimetrÃ­a en la base de clientes: una mayorÃ­a con baja actividad y una minorÃ­a altamente activa.\n",
        "\n",
        "ðŸ”¹Conclusiones\n",
        "* **DistribuciÃ³n Sesgada**:\n",
        "  * El sesgo del target puede afectar la capacidad de los modelos de regresiÃ³n para generalizar correctamente, especialmente si el objetivo es predecir con precisiÃ³n los valores mÃ¡s altos (clientes altamente activos).\n",
        "* **TransformaciÃ³n Recomendada**:\n",
        "  * Aplicar una transformaciÃ³n logarÃ­tmica o raÃ­z cuadrada podrÃ­a reducir la asimetrÃ­a y estabilizar la varianza, facilitando un aprendizaje mÃ¡s equilibrado por parte del modelo. Esta decisiÃ³n dependerÃ¡ de si se prioriza mejorar el ajuste general o capturar mejor los valores extremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "594m5Ue0N4jb",
        "outputId": "8d2b2d0e-4028-4e4a-8e44-5470a4bf7d05"
      },
      "outputs": [],
      "source": [
        "# Aplicar una transformaciÃ³n logarÃ­tmica al target para reducir el sesgo\n",
        "df_copia['total_transacciones_anual_log'] = np.log1p(df_copia['total_transacciones_anual'])\n",
        "\n",
        "# Visualizar la distribuciÃ³n del target transformado\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df_copia['total_transacciones_anual_log'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('DistribuciÃ³n del Target Transformado (Histograma)')\n",
        "plt.xlabel('Log(1 + Total de Transacciones Anual)')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(df_copia['total_transacciones_anual_log'].dropna(), color='blue')\n",
        "plt.title('DistribuciÃ³n del Target Transformado (Densidad)')\n",
        "plt.xlabel('Log(1 + Total de Transacciones Anual)')\n",
        "plt.ylabel('Densidad')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avie3c_OOfb5"
      },
      "source": [
        "ðŸ”¹EvaluaciÃ³n de la TransformaciÃ³n LogarÃ­tmica del Target\n",
        "\n",
        "La aplicaciÃ³n de una transformaciÃ³n logarÃ­tmica al target ha generado mejoras significativas en su distribuciÃ³n, lo que tiene implicancias directas sobre la calidad del modelado.\n",
        "* **DistribuciÃ³n MÃ¡s SimÃ©trica**:\n",
        "  * Tras la transformaciÃ³n, los valores del target se distribuyen de forma mÃ¡s equilibrada alrededor del centro. La forma de la curva se aproxima a una distribuciÃ³n normal, lo que favorece el uso de modelos que asumen simetrÃ­a en los residuos.\n",
        "* **ReducciÃ³n del Sesgo**:\n",
        "  * El sesgo positivo presente en los datos originales â€”concentraciÃ³n en valores bajos y una cola larga hacia la derechaâ€” se ha mitigado. Esto reduce la influencia desproporcionada de los valores extremos sobre el ajuste del modelo.\n",
        "* **Beneficios para el Modelado Predictivo**:\n",
        "  * Una distribuciÃ³n mÃ¡s balanceada permite que los algoritmos de regresiÃ³n capturen relaciones con mayor precisiÃ³n a lo largo de todo el rango del target. Esto puede traducirse en:\n",
        "    * Mejor capacidad de generalizaciÃ³n.\n",
        "    * ReducciÃ³n del error en predicciones extremas.\n",
        "    * Menor sensibilidad a outliers.\n",
        "\n",
        "ðŸ”¹JustificaciÃ³n del Uso de np.log1p para la TransformaciÃ³n del Target\n",
        "\n",
        "Se utilizÃ³ np.log1p(x) en lugar de np.log(x) para transformar el target debido a las siguientes razones:\n",
        "* **Manejo de ceros sin errores**:\n",
        "  * A diferencia de np.log(x), que no admite valores iguales a cero (lo que generarÃ­a un error o -inf), np.log1p(x) calcula log(1 + x), permitiendo transformar valores cero de forma segura. Esto es especialmente relevante en contextos donde el target puede representar conteos o montos que incluyen ceros.\n",
        "* **Estabilidad numÃ©rica**:\n",
        "  * np.log1p ofrece mayor precisiÃ³n para valores pequeÃ±os de x, evitando errores de redondeo o pÃ©rdida de informaciÃ³n significativa que puede ocurrir con np.log(1 + x) de forma manual.\n",
        "* **ConservaciÃ³n de la escala relativa**:\n",
        "  * Aunque suaviza menos que una logaritmizaciÃ³n mÃ¡s agresiva, np.log1p mantiene relaciones proporcionales importantes para modelos de regresiÃ³n que requieren interpretar variaciones relativas.\n",
        "* **ConclusiÃ³n**:\n",
        "  * El uso de np.log1p garantiza una transformaciÃ³n segura, estable y efectiva del target, facilitando una mejor distribuciÃ³n sin comprometer la integridad de los datos.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BgWYI1KG3dp"
      },
      "source": [
        "## Modelado\n",
        "\n",
        "En esta etapa se implementan modelos de machine learning con el objetivo de identificar patrones en el comportamiento de los clientes y predecir su probabilidad de retenciÃ³n.\n",
        "\n",
        "ðŸ”¹Objetivo del Modelado\n",
        "\n",
        "El propÃ³sito principal es construir un modelo supervisado capaz de clasificar a los clientes en funciÃ³n de su comportamiento financiero, especÃ­ficamente en relaciÃ³n con su nivel de actividad transaccional anual (target binarizado). Este tipo de anÃ¡lisis es clave para anticipar abandono o desuso de productos financieros y orientar campaÃ±as de retenciÃ³n.\n",
        "\n",
        "ðŸ”¹Modelos Considerados\n",
        "\n",
        "* **RegresiÃ³n LogÃ­stica**:\n",
        "  * Modelo base de clasificaciÃ³n binaria, Ãºtil por su interpretabilidad y capacidad para manejar relaciones lineales entre variables independientes y la probabilidad de una clase (en este caso, clientes con alta o baja actividad).\n",
        "* **Ãrboles de DecisiÃ³n**:\n",
        "  * Utilizados como alternativa mÃ¡s flexible, permiten capturar relaciones no lineales y generan reglas claras para interpretar la segmentaciÃ³n de clientes. Son especialmente Ãºtiles en entornos con mÃºltiples variables categÃ³ricas y umbrales de decisiÃ³n.\n",
        "* **K-Means (Clustering)**:\n",
        "  * Aplicado como mÃ©todo no supervisado para segmentar clientes en grupos segÃºn similitudes en sus patrones de uso. Este anÃ¡lisis complementa el modelado supervisado, ya que permite descubrir perfiles ocultos en la base de clientes, incluso sin etiquetas explÃ­citas.\n",
        "\n",
        "ðŸ”¹PreparaciÃ³n de los Datos para el Modelado\n",
        "* **DivisiÃ³n de Datos**:\n",
        "  * El dataset se divide en un conjunto de entrenamiento (80%) y uno de prueba (20%) mediante train_test_split, garantizando que la evaluaciÃ³n del modelo se realice sobre datos no vistos.\n",
        "* **ValidaciÃ³n Cruzada**:\n",
        "  * En el caso de modelos supervisados como la regresiÃ³n logÃ­stica, se emplea validaciÃ³n cruzada (k-fold) para evaluar la estabilidad del modelo y prevenir el sobreajuste. Esto permite obtener mÃ©tricas mÃ¡s robustas en escenarios con alta varianza.\n",
        "* **EstandarizaciÃ³n y CodificaciÃ³n**:\n",
        "  * Se construye un pipeline de preprocesamiento que transforma las variables numÃ©ricas (escaladas con StandardScaler) y categÃ³ricas (codificadas con OneHotEncoder), permitiendo que el modelo procese adecuadamente las distintas escalas y tipos de variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPt8gU06IiXZ"
      },
      "outputs": [],
      "source": [
        "# SelecciÃ³n de features y target (con transformaciÃ³n logarÃ­tmica)\n",
        "X = df_copia.drop(columns=['total_transacciones_anual', 'total_transacciones_anual_log'])  # todas las columnas menos el target\n",
        "y = df_copia['total_transacciones_anual_log']  # el target log-transformado\n",
        "\n",
        "# DivisiÃ³n de los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BLFxj1Koune"
      },
      "source": [
        "ðŸ”¹DivisiÃ³n de Variables y SeparaciÃ³n de Datos\n",
        "\n",
        "1. **SelecciÃ³n de Variables Predictoras (X) y Target (y)**\n",
        "* Se define `X` como el subconjunto de variables independientes, excluyendo tanto el target original (`total_transacciones_anual`) como su transformaciÃ³n (`total_transacciones_anual_log`), para evitar fuga de informaciÃ³n durante el entrenamiento.\n",
        "* La variable objetivo y corresponde a `total_transacciones_anual_log`, una transformaciÃ³n logarÃ­tmica del total de transacciones anuales. Esta transformaciÃ³n permite suavizar la distribuciÃ³n del target y mejora el rendimiento en modelos sensibles al sesgo como la regresiÃ³n lineal.\n",
        "\n",
        "2. **DivisiÃ³n del Dataset en Entrenamiento y Prueba**\n",
        "* Se utiliza `train_test_split` para dividir el dataset en un conjunto de entrenamiento (`80%`) y otro de prueba (`20%`).\n",
        "* El parÃ¡metro `random_state=42` garantiza la reproducibilidad del experimento, asegurando que la particiÃ³n de datos sea consistente a lo largo de ejecuciones sucesivas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEaf_Y0NNUf5",
        "outputId": "f94c6f37-7beb-49ff-80dd-59b0cead2d91"
      },
      "outputs": [],
      "source": [
        "# Identificar columnas que son de tipo `object`\n",
        "object_columns = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Intentar convertir columnas numÃ©ricas con formato de coma decimal\n",
        "for col in object_columns:\n",
        "    try:\n",
        "        # Reemplazar comas con puntos y convertir a float\n",
        "        X[col] = X[col].str.replace(',', '.').astype(float)\n",
        "        print(f\"Columna {col} convertida a numÃ©rica con Ã©xito.\")\n",
        "    except ValueError:\n",
        "        print(f\" /!\\ Advertencia: Columna '{col}' no se pudo convertir a numÃ©rica, aÃºn contiene valores no numÃ©ricos.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npNpkKv5o_km"
      },
      "source": [
        "ðŸ”¹ConversiÃ³n de Columnas CategÃ³ricas Mal Tipadas a Formato NumÃ©rico\n",
        "\n",
        "Este bloque de cÃ³digo estandariza columnas originalmente clasificadas como object que, en realidad, contienen datos numÃ©ricos representados con comas decimales (formato comÃºn en regiones hispanohablantes).\n",
        "\n",
        "* **DetecciÃ³n de Columnas ProblemÃ¡ticas**\n",
        "  * Se identifican todas las columnas con tipo de dato `object`, ya que estas pueden contener valores numÃ©ricos mal interpretados como texto por el parser inicial (por ejemplo, `982,45`).\n",
        "* **NormalizaciÃ³n del Formato NumÃ©rico**\n",
        "  * Para cada columna identificada, se reemplazan las comas por puntos (',' â†’ '.') y se intenta convertir los valores a tipo `float`.\n",
        "  * Las conversiones exitosas se notifican con un mensaje informativo; si la conversiÃ³n falla (por ejemplo, por contener texto irreconciliable con una representaciÃ³n numÃ©rica), se genera una advertencia controlada.\n",
        "\n",
        "Este paso es fundamental para evitar errores durante el preprocesamiento y asegurar que todas las variables numÃ©ricas estÃ©n en el formato adecuado para el anÃ¡lisis y modelado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Fswv68LxZ4",
        "outputId": "eeea02f3-0a96-4370-b632-286b8fb3fee8"
      },
      "outputs": [],
      "source": [
        "# Detectar columnas categÃ³ricas en el DataFrame X\n",
        "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Identificar quÃ© columnas pueden utilizar LabelEncoder y cuÃ¡les requieren OneHotEncoder\n",
        "label_encode_cols = []\n",
        "onehot_encode_cols = []\n",
        "\n",
        "# Iterar sobre las columnas categÃ³ricas y contar las categorÃ­as Ãºnicas\n",
        "for col in categorical_columns:\n",
        "    unique_values = X[col].nunique()\n",
        "\n",
        "    if unique_values == 2:\n",
        "        # Si tiene solo dos categorÃ­as, se puede usar LabelEncoder\n",
        "        label_encode_cols.append(col)\n",
        "    else:\n",
        "        # Si tiene mÃ¡s de dos categorÃ­as, se recomienda OneHotEncoder\n",
        "        onehot_encode_cols.append(col)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Columnas para LabelEncoder (2 categorÃ­as):\", label_encode_cols)\n",
        "print(\"Columnas para OneHotEncoder (mÃ¡s de 2 categorÃ­as):\", onehot_encode_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNbqhEzQpVG3"
      },
      "source": [
        "ðŸ”¹ClasificaciÃ³n de Variables CategÃ³ricas para CodificaciÃ³n\n",
        "\n",
        "Este bloque organiza las columnas categÃ³ricas en funciÃ³n del tipo de codificaciÃ³n mÃ¡s apropiado, optimizando asÃ­ su tratamiento antes del modelado.\n",
        "\n",
        "* **IdentificaciÃ³n de Columnas CategÃ³ricas**\n",
        "  * Se seleccionan todas las columnas en `X` con tipo `object` o `category`, lo que usualmente representa variables con etiquetas no numÃ©ricas (por ejemplo, gÃ©nero, regiÃ³n, tipo de producto).\n",
        "* **SegmentaciÃ³n segÃºn NÃºmero de CategorÃ­as**\n",
        "  * Cada columna categÃ³rica se analiza segÃºn su cardinalidad (cantidad de valores Ãºnicos).\n",
        "    * Si tiene exactamente dos categorÃ­as, se asigna a `label_encode_cols`, ya que puede representarse eficientemente con `LabelEncoder`.\n",
        "    * Si tiene mÃ¡s de dos categorÃ­as, se asigna a `onehot_encode_cols`, ya que `OneHotEncoder` evita introducir orden implÃ­cito en variables no ordinales.\n",
        "* **Resultado del AnÃ¡lisis**\n",
        "  * Se imprime una lista diferenciada de columnas segÃºn el tipo de codificaciÃ³n recomendado. Esto facilita el diseÃ±o posterior del pipeline de preprocesamiento, asegurando un tratamiento correcto de las variables categÃ³ricas en el modelo.\n",
        "\n",
        "Este paso es crucial para garantizar que el modelo reciba entradas numÃ©ricas bien estructuradas, evitando sesgos implÃ­citos y mejorando su rendimiento general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk1c4U-wNeEY"
      },
      "outputs": [],
      "source": [
        "# Aplicar LabelEncoder a las columnas binarias\n",
        "for col in label_encode_cols:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "# Aplicar OneHotEncoder a las columnas con mÃ¡s de 2 categorÃ­as\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=True)\n",
        "X_encoded = encoder.fit_transform(X[onehot_encode_cols])\n",
        "\n",
        "# Combinar las caracterÃ­sticas numÃ©ricas y categÃ³ricas codificadas\n",
        "X_rest = X.drop(columns=onehot_encode_cols)\n",
        "X_sparse = hstack([X_rest, X_encoded])\n",
        "\n",
        "# DivisiÃ³n en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sparse, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcPPIl4ppgAZ"
      },
      "source": [
        "ðŸ”¹CodificaciÃ³n de Variables CategÃ³ricas y PreparaciÃ³n Final de Datos\n",
        "\n",
        "* **CodificaciÃ³n con LabelEncoder**\n",
        "  * Se aplica a columnas binarias (`label_encode_cols`) para transformarlas directamente en valores numÃ©ricos (`0` y `1`), manteniendo la estructura original sin expansiÃ³n dimensional.\n",
        "* **CodificaciÃ³n con OneHotEncoder**\n",
        "  * Para columnas con mÃ¡s de dos categorÃ­as (`onehot_encode_cols`), se utiliza `OneHotEncoder` con `drop='first'` para evitar multicolinealidad.\n",
        "  * La opciÃ³n `sparse_output=True` genera una matriz dispersa eficiente en memoria.\n",
        "* **IntegraciÃ³n del Dataset Codificado**\n",
        "  * `X_rest` conserva las columnas no categÃ³ricas.\n",
        "  * La matriz final `X_sparse` se obtiene al combinar `X_rest` con la matriz codificada `X_encoded` mediante `hstack`, integrando variables categÃ³ricas y numÃ©ricas en una estructura apta para el modelado.\n",
        "* **DivisiÃ³n de Datos**\n",
        " * Los datos se dividen en conjuntos de entrenamiento y prueba (`X_train`, `X_test`, `y_train`, `y_test`) mediante `train_test_split`, reservando el 20% para validaciÃ³n (`test_size=0.2`) y asegurando reproducibilidad con `random_state=42`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V9SIlB1Ofdd"
      },
      "outputs": [],
      "source": [
        "# ImputaciÃ³n de NaN con la mÃ¡s frecuente de cada columna\n",
        "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Axa1HfCp19D"
      },
      "source": [
        "ðŸ”¹ImputaciÃ³n de Valores Faltantes con SimpleImputer\n",
        "* **DefiniciÃ³n del Imputador**\n",
        "  * Se utiliza `SimpleImputer(strategy=\"most_frequent\")` para reemplazar los valores nulos (`NaN`) por el valor mÃ¡s frecuente de cada columna. Esta estrategia es Ãºtil para variables categÃ³ricas o numÃ©ricas discretas con una moda dominante.\n",
        "* **AplicaciÃ³n en el Conjunto de Entrenamiento**\n",
        "  * `fit_transform(X_train)` ajusta el imputador aprendiendo el valor mÃ¡s frecuente de cada columna y lo aplica inmediatamente sobre `X_train`, garantizando consistencia interna.\n",
        "* **AplicaciÃ³n en el Conjunto de Prueba**\n",
        "  * `transform(X_test)` aplica la imputaciÃ³n aprendida desde `X_train` a `X_test`, asegurando que no se introduzca informaciÃ³n del conjunto de prueba durante el entrenamiento (principio de no-leakage)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZLUQWnJKj23",
        "outputId": "52a06b5c-18d1-42d3-d097-c499dcc89b36"
      },
      "outputs": [],
      "source": [
        "# Entrenar un modelo de RegresiÃ³n Lineal\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Realizar predicciones con validaciÃ³n cruzada\n",
        "y_pred_cv = cross_val_predict(linear_model, X_train, y_train, cv=4)\n",
        "\n",
        "# Calcular las mÃ©tricas en validaciÃ³n cruzada\n",
        "mse_cv = mean_squared_error(y_train, y_pred_cv)\n",
        "mae_cv = mean_absolute_error(y_train, y_pred_cv)\n",
        "rmse_cv = np.sqrt(mse_cv)\n",
        "\n",
        "print(f\"MSE RegresiÃ³n Lineal: {mse_cv:.4f}\")\n",
        "print(f\"MAE RegresiÃ³n Lineal: {mae_cv:.4f}\")\n",
        "print(f\"RMSE RegresiÃ³n Lineal: {rmse_cv:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPITPpu8qG3W"
      },
      "source": [
        "ðŸ”¹EvaluaciÃ³n del Modelo de RegresiÃ³n Lineal (Baseline)\n",
        "\n",
        "Este modelo fue utilizado Ãºnicamente como baseline inicial para establecer un punto de comparaciÃ³n. No se considera adecuado para producciÃ³n debido a limitaciones en su rendimiento predictivo.\n",
        "\n",
        "1. **Entrenamiento y EvaluaciÃ³n**\n",
        "* **Modelo**: `LinearRegression()`\n",
        "* **Entrenamiento**: Se ajustÃ³ sobre los datos `X_train` y `y_train`.\n",
        "* **ValidaciÃ³n cruzada**: Se utilizÃ³ cross_val_score con 4 pliegues (`cv=4`), evaluando con la mÃ©trica neg_mean_squared_error.\n",
        "* **Promedio del MSE**: Se calculÃ³ invirtiendo el signo de la media para interpretar el error en forma positiva.\n",
        "\n",
        "2. **Resultados**\n",
        "* **MSE (Mean Squared Error)**: ~0.31\n",
        "  * Refleja un error cuadrÃ¡tico promedio bajo en la escala logarÃ­tmica del target (log(1 + transacciones)), que va aproximadamente de 0 a 6.\n",
        "* **MAE (Mean Absolute Error)**: ~0.43\n",
        "  * Indica que la desviaciÃ³n promedio de las predicciones es de 0.43 unidades en la escala logarÃ­tmica.\n",
        "* **RMSE (Root Mean Squared Error)**: ~0.55\n",
        "  * Proporciona una mÃ©trica mÃ¡s intuitiva de error promedio. En este caso, tambiÃ©n es bajo, lo que implica que no hay errores extremos frecuentes.\n",
        "\n",
        "3. **ConclusiÃ³n**\n",
        "Aunque los errores obtenidos son bajos en tÃ©rminos absolutos, la regresiÃ³n lineal no captura relaciones no lineales ni interacciones complejas entre variables. Por ello, aunque sirve como referencia inicial, se requiere un modelo mÃ¡s robusto para mejorar la capacidad predictiva y explotar mejor la estructura del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOBewSsYv5F-",
        "outputId": "736ff131-0843-4a8a-aec6-7a931ff93309"
      },
      "outputs": [],
      "source": [
        "# Paso 1: Convertir variables categÃ³ricas en X a numÃ©ricas usando OneHotEncoder\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Paso 2: Concatenar X_encoded e y en un Ãºnico DataFrame para el cÃ¡lculo de la correlaciÃ³n\n",
        "if 'target' in X_encoded.columns:\n",
        "    X_encoded = X_encoded.drop(columns='target')\n",
        "df_combined = pd.concat([X_encoded, y.rename(\"target\")], axis=1)\n",
        "\n",
        "# Paso 3: Calcular la matriz de correlaciÃ³n en el DataFrame combinado\n",
        "correlation_matrix = df_combined.corr()\n",
        "\n",
        "# Paso 4: Extraer la fila de correlaciÃ³n del target y ordenarla usando 'by'\n",
        "try:\n",
        "    # Filtramos las correlaciones con respecto al 'target', convirtiÃ©ndolas en un DataFrame si es necesario\n",
        "    target_correlation = correlation_matrix[['target']].drop(index='target').sort_values(by='target', ascending=False)\n",
        "\n",
        "    # Mostrar las 10 caracterÃ­sticas con mayor correlaciÃ³n con el target\n",
        "    print(\"Top 10 features mÃ¡s correlacionados con el target:\")\n",
        "    print(target_correlation.head(10))\n",
        "except KeyError:\n",
        "    print(\"Error: La columna 'target' no se encuentra en correlation_matrix.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KdfGIBtu46l"
      },
      "source": [
        "ðŸ”¹SelecciÃ³n del Target para Modelos de ClasificaciÃ³n\n",
        "\n",
        "* **Target elegido**: Probabilidad de RetenciÃ³n de Clientes\n",
        "  * **DefiniciÃ³n**: ClasificaciÃ³n binaria que distingue entre clientes con alta probabilidad de abandono y aquellos con baja probabilidad de abandono.\n",
        "    *  Esta variable se puede construir a partir de indicadores como frecuencia de transacciones, antigÃ¼edad, uso de productos financieros y niveles de actividad reciente.\n",
        "  * **JustificaciÃ³n de Negocio**\n",
        "    * Este target es altamente accionable. Permite a Dormammu identificar clientes en riesgo de fuga y diseÃ±ar estrategias de retenciÃ³n proactiva. Al anticipar la pÃ©rdida de clientes, el banco puede intervenir con ofertas personalizadas, campaÃ±as de fidelizaciÃ³n o ajustes en productos, mejorando la rentabilidad a largo plazo y reduciendo los costos de adquisiciÃ³n de nuevos clientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "k45_qqKs3FF8"
      },
      "outputs": [],
      "source": [
        "# Filtrar solo columnas numÃ©ricas para escalamiento\n",
        "num_features = X.select_dtypes(include=[np.number]).columns\n",
        "X[num_features] = StandardScaler().fit_transform(X[num_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrNvoCZOgNQB",
        "outputId": "2f20b77d-2766-4e11-fe2a-88da4c72825e"
      },
      "outputs": [],
      "source": [
        "# CodificaciÃ³n One-Hot de variables categÃ³ricas con mÃ¡s de dos categorÃ­as\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "categorical_features = ['Region', 'IndRev_T01']\n",
        "X_encoded = encoder.fit_transform(X[categorical_features])\n",
        "\n",
        "# Combinar las caracterÃ­sticas codificadas con el resto del DataFrame\n",
        "X_rest = X.drop(columns=categorical_features)\n",
        "X_final = pd.concat([pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_features)), X_rest.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# VerificaciÃ³n del resultado\n",
        "print(\"Primeras filas del DataFrame codificado:\")\n",
        "print(X_final.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWyjyNCP9TNP"
      },
      "source": [
        "ðŸ”¹TransformaciÃ³n de Atributos para Modelos de ClasificaciÃ³n\n",
        "\n",
        "Para adaptar el conjunto de datos a modelos de clasificaciÃ³n, se realizÃ³ la transformaciÃ³n de variables categÃ³ricas mediante codificaciÃ³n One-Hot, asegurando que todas las columnas estÃ©n en formato numÃ©rico y apropiadas para aprendizaje supervisado.\n",
        "\n",
        "1. **CodificaciÃ³n One-Hot**\n",
        "* **Objetivo**: Convertir variables categÃ³ricas como `Region` o `IndRev_T01` en un formato binario interpretable por modelos de machine learning.\n",
        "* **MÃ©todo**: Cada categorÃ­a Ãºnica se transforma en una columna binaria (`0` o `1`). Se utilizÃ³ `drop='first'` para evitar colinealidad entre variables generadas.\n",
        "* **Ejemplo de columnas resultantes**: `Region_2.0`, `Region_3.0`, etc., indican presencia de cada categorÃ­a.\n",
        "\n",
        "2. **IntegraciÃ³n con el Dataset**\n",
        "* Las variables codificadas se combinaron con las variables numÃ©ricas originales y derivadas para conformar el conjunto final (`X_final`).\n",
        "* El resultado es una matriz de caracterÃ­sticas puramente numÃ©rica, lista para alimentar modelos de clasificaciÃ³n como regresiÃ³n logÃ­stica, Ã¡rboles de decisiÃ³n, o modelos basados en boosting.\n",
        "\n",
        "3. **InspecciÃ³n del Resultado**\n",
        "* Las primeras filas de `X_final` muestran la correcta conversiÃ³n de variables categÃ³ricas y la conservaciÃ³n de variables numÃ©ricas clave como Edad, Renta, AntigÃ¼edad, y diversos indicadores de actividad financiera.\n",
        "* El dataset resultante ofrece una representaciÃ³n estructurada y compatible con tÃ©cnicas de modelado modernas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "T8bqQdbmdwhi",
        "outputId": "4894f20e-448a-4b76-a31b-8c508816c2e2"
      },
      "outputs": [],
      "source": [
        "# VisualizaciÃ³n de la correlaciÃ³n entre caracterÃ­sticas seleccionadas\n",
        "\n",
        "# SelecciÃ³n de caracterÃ­sticas especÃ­ficas para la matriz de correlaciÃ³n\n",
        "selected_features = ['Edad', 'Renta', 'Antiguedad', 'CUPO_L1', 'CUPO_L2', 'CUPO_MX']\n",
        "\n",
        "# Generar la matriz de correlaciÃ³n solo para las caracterÃ­sticas seleccionadas\n",
        "correlation_matrix = X[selected_features].corr()\n",
        "\n",
        "# Visualizar la matriz de correlaciÃ³n\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar_kws={'label': 'CorrelaciÃ³n'})\n",
        "plt.title(\"Matriz de CorrelaciÃ³n de CaracterÃ­sticas NumÃ©ricas \")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx23WZJ4CTIe"
      },
      "source": [
        "ðŸ”¹AnÃ¡lisis de CorrelaciÃ³n entre Variables NumÃ©ricas\n",
        "\n",
        "La matriz de correlaciÃ³n presentada analiza la relaciÃ³n lineal entre seis variables clave: `Edad`, `Renta`, `AntigÃ¼edad`, `CUPO_L1`, `CUPO_L2` y `CUPO_MX`. Los coeficientes de correlaciÃ³n oscilan entre -1 y 1, donde:\n",
        "\n",
        "* +1: CorrelaciÃ³n positiva perfecta.\n",
        "* -1: CorrelaciÃ³n negativa perfecta.\n",
        "* 0: Ausencia de correlaciÃ³n lineal.\n",
        "\n",
        "Principales Hallazgos\n",
        "* **`CUPO_L1` vs. `CUPO_MX` (r = 0.66)**\n",
        "  * Existe una correlaciÃ³n moderadamente alta entre el lÃ­mite de compras nacionales (`CUPO_L1`) y el cupo internacional (`CUPO_MX`), lo que indica que ambos lÃ­mites suelen escalar juntos, probablemente debido a polÃ­ticas crediticias internas.\n",
        "* **`CUPO_L1` vs. `AntigÃ¼edad` (r = 0.40)**\n",
        "  * Los clientes con mayor antigÃ¼edad tienden a tener un lÃ­mite de crÃ©dito mÃ¡s alto, lo cual es consistente con prÃ¡cticas financieras donde la estabilidad en el tiempo es un factor de confianza.\n",
        "* **`Edad` vs. `AntigÃ¼edad` (r = 0.36) y `CUPO_L1` (r = 0.26)**\n",
        "  * La edad tiene una correlaciÃ³n moderada con la antigÃ¼edad y leve con los lÃ­mites de crÃ©dito, sugiriendo cierta influencia del perfil etario, aunque no es un predictor dominante.\n",
        "* **`Renta` vs. `LÃ­mites de CrÃ©dito` (r â‰ˆ 0.25)**\n",
        "  * A pesar de ser una variable financiera clave, la renta muestra correlaciones relativamente bajas con los cupos de crÃ©dito. Esto podrÃ­a indicar que el otorgamiento de cupo considera otros factores como historial de pago o segmentaciÃ³n comercial.\n",
        "* **Ausencia de Multicolinealidad CrÃ­tica**\n",
        "  * No se detectan correlaciones extremas (por encima de 0.8 o por debajo de -0.8), lo cual es positivo para el modelado. Las variables aportan informaciÃ³n diferenciada y no redundante, reduciendo el riesgo de multicolinealidad.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hMyvmuNUY-p"
      },
      "source": [
        "### Random Forest + Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYsFdvxdh9x4",
        "outputId": "d9c32abf-8fd3-4350-93fb-5bc8564b2f93"
      },
      "outputs": [],
      "source": [
        "# Resumen de valores nulos antes del preprocesamiento\n",
        "print(\"Resumen de valores nulos antes del preprocesamiento:\")\n",
        "print(X.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMwk6UxfjH-a"
      },
      "source": [
        "ðŸ”¹RevisiÃ³n de Completitud de Datos\n",
        "\n",
        "Tras ejecutar una revisiÃ³n posterior de los valores nulos en el conjunto de datos, se confirma que todas las columnas estÃ¡n completamente pobladas. Variables clave como `Id`, `Subsegmento`, `Sexo`, `Region`, `Edad`, `UsoL1_T01`, `IndRev_T01` y `target` no presentan valores faltantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If_zw9lmZkoy"
      },
      "outputs": [],
      "source": [
        "# Definir las caracterÃ­sticas numÃ©ricas y categÃ³ricas (modifica segÃºn tus variables)\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocesamiento para caracterÃ­sticas numÃ©ricas (imputaciÃ³n y escalado)\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "# Preprocesamiento para caracterÃ­sticas categÃ³ricas (imputaciÃ³n y codificaciÃ³n)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Crear el preprocesador usando ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Verificar y transformar `y` en una variable binaria si es continuo\n",
        "if y.dtype == 'float' or y.dtype == 'int':\n",
        "    threshold = np.median(y)\n",
        "    y = np.where(y >= threshold, 1, 0)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear el pipeline con el preprocesador y el modelo\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', LogisticRegression(max_iter=1000))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fstaa0JcaGXM",
        "outputId": "90744769-f195-4872-f1e3-8fb8a5d04e8f"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# EvaluaciÃ³n\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"EvaluaciÃ³n del modelo (Random Forest + Pipeline):\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "print(\"Matriz de confusiÃ³n:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX59SHC5aPy3",
        "outputId": "d9d1226e-df00-45bd-b3af-74c416b06d1d"
      },
      "outputs": [],
      "source": [
        "# Guardar el pipeline entero (preprocesamiento + modelo)\n",
        "joblib.dump(pipeline, 'models/modelo_pipeline_rf.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv3MNqwxaRuz"
      },
      "outputs": [],
      "source": [
        "# Cargar modelo\n",
        "modelo_cargado = joblib.load('models/modelo_pipeline_rf.pkl')\n",
        "\n",
        "# Predecir directamente con el pipeline\n",
        "y_pred_cargado = modelo_cargado.predict(X_test)\n",
        "\n",
        "# EvaluaciÃ³n para verificar consistencia\n",
        "print(\"EvaluaciÃ³n del modelo cargado:\")\n",
        "print(classification_report(y_test, y_pred_cargado, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4l2l5A4nFdb"
      },
      "source": [
        "ðŸ”¹EvaluaciÃ³n del Modelo: Exactitud e Implicaciones\n",
        "\n",
        "* **Exactitud Obtenida**\n",
        "  * El modelo alcanzÃ³ una exactitud del 96%, lo cual representa un rendimiento sobresaliente considerando las variables utilizadas. Este nivel de desempeÃ±o sugiere que las caracterÃ­sticas disponibles en el dataset son efectivas para capturar los patrones necesarios para la clasificaciÃ³n.\n",
        "* **InterpretaciÃ³n y Consideraciones para Mejora**\n",
        "  * La exclusiÃ³n de ciertas columnas no afectÃ³ negativamente el rendimiento del modelo, lo que indica que dichas variables probablemente no aportaban informaciÃ³n crÃ­tica en su estado actual.\n",
        "  * No obstante, si estas columnas contienen informaciÃ³n futura o si se reduce el sesgo de disponibilidad (por ejemplo, completando valores faltantes con estrategias robustas), podrÃ­an evaluarse nuevamente para determinar si contribuyen a mejorar la capacidad predictiva.\n",
        "  * En el caso de variables categÃ³ricas, una estrategia mÃ¡s sÃ³lida que la eliminaciÃ³n podrÃ­a ser asignar una categorÃ­a explÃ­cita para valores faltantes (como \"Desconocido\"), preservando la informaciÃ³n estructural del dataset sin introducir ruido estadÃ­stico innecesario.\n",
        "\n",
        "ðŸ”¹ConclusiÃ³n\n",
        "\n",
        "El modelo demostrÃ³ ser eficaz incluso con un subconjunto reducido de variables, lo cual refuerza su robustez y eficiencia. Sin embargo, se recomienda seguir evaluando el valor agregado de variables omitidas a medida que se disponga de datos mÃ¡s completos.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hGpwMKkf6DQ"
      },
      "source": [
        "**Reconocer Overfitting y Underfitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWwjyYXVgAFP",
        "outputId": "60579bac-5872-49df-a7f2-b2d0615c3780"
      },
      "outputs": [],
      "source": [
        "# Calcular la exactitud en el conjunto de entrenamiento y en el conjunto de prueba\n",
        "train_accuracy = accuracy_score(y_train, pipeline.predict(X_train))\n",
        "test_accuracy = accuracy_score(y_test, pipeline.predict(X_test))\n",
        "\n",
        "print(f\"Exactitud en entrenamiento: {train_accuracy:.2f}\")\n",
        "print(f\"Exactitud en prueba: {test_accuracy:.2f}\")\n",
        "\n",
        "# InterpretaciÃ³n de overfitting o underfitting\n",
        "if train_accuracy > test_accuracy + 0.1:\n",
        "    print(\"Posible overfitting detectado: el modelo tiene un desempeÃ±o mucho mejor en entrenamiento que en prueba.\")\n",
        "elif test_accuracy > train_accuracy:\n",
        "    print(\"Posible underfitting detectado: el modelo no estÃ¡ capturando patrones suficientemente bien.\")\n",
        "else:\n",
        "    print(\"Buen ajuste: el modelo tiene un desempeÃ±o balanceado entre entrenamiento y prueba.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJx2A-4km6LN",
        "outputId": "0eda80d6-b6d2-4fea-8ab9-7b086b7d5da5"
      },
      "outputs": [],
      "source": [
        "# Calcular la exactitud en el conjunto de entrenamiento y en el conjunto de prueba\n",
        "train_accuracy = accuracy_score(y_train, pipeline.predict(X_train))\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Exactitud en entrenamiento: {train_accuracy:.2f}\")\n",
        "print(f\"Exactitud en prueba: {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLOa6GHKqgyI"
      },
      "source": [
        "ðŸ”¹EvaluaciÃ³n del Ajuste del Modelo: Overfitting vs. Underfitting\n",
        "\n",
        "* **AnÃ¡lisis del DesempeÃ±o**:\n",
        "  * Para evaluar el comportamiento del modelo, se comparÃ³ su rendimiento en los conjuntos de entrenamiento y prueba utilizando la mÃ©trica de exactitud (accuracy):\n",
        "    * Exactitud en entrenamiento: 97%\n",
        "    * Exactitud en prueba: 96%\n",
        "\n",
        "* **InterpretaciÃ³n**:\n",
        "  * La diferencia marginal entre ambos conjuntos sugiere que el modelo generaliza adecuadamente y no presenta overfitting (sobreajuste).\n",
        "  * Asimismo, dado que ambos resultados son altos, el modelo tampoco evidencia underfitting (subajuste), es decir, logra captar patrones relevantes sin sobreajustarse a los datos de entrenamiento.\n",
        "\n",
        "* **Mensajes de Advertencia**:\n",
        "  * Se emitieron advertencias relacionadas con columnas que no contienen valores observados (como 'Sexo' o 'IndRev_T12'). Estas advertencias se refieren a omisiones automÃ¡ticas en el proceso de imputaciÃ³n, pero no impactan negativamente el rendimiento del modelo, ya que dichas columnas no contenÃ­an informaciÃ³n Ãºtil o estaban correctamente gestionadas en etapas anteriores del preprocesamiento.\n",
        "\n",
        "ðŸ”¹ConclusiÃ³n\n",
        "\n",
        "El modelo logra un buen equilibrio entre sesgo y varianza, lo que lo convierte en una base sÃ³lida para aplicaciones predictivas con los datos actuales. No obstante, es recomendable seguir monitoreando este equilibrio si se incorporan nuevas variables o si se modifica la estrategia de imputaciÃ³n.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEvl7YgfuVz2"
      },
      "source": [
        "**MÃ©tricas de EvaluaciÃ³n de Modelos de ClasificaciÃ³n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjzr5kXsoC4W",
        "outputId": "3dc4e14c-3433-4c49-ce0f-6f67f7c62f83"
      },
      "outputs": [],
      "source": [
        "# Reporte de clasificaciÃ³n detallado\n",
        "print(\"Reporte de ClasificaciÃ³n:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-ROH3rdufy_"
      },
      "source": [
        "ðŸ”¹EvaluaciÃ³n del Modelo: MÃ©tricas de ClasificaciÃ³n\n",
        "\n",
        "Se evaluÃ³ el rendimiento del modelo utilizando las mÃ©tricas estÃ¡ndar: precisiÃ³n, recall, F1-score y exactitud, aplicadas a cada clase del target.\n",
        "\n",
        "ðŸ”¹Resultados principales\n",
        "\n",
        "| Clase    | Precision | Recall | F1-score | Soporte |\n",
        "| -------- | --------- | ------ | -------- | ------- |\n",
        "| 0        | 0.96      | 0.96   | 0.96     | 2716    |\n",
        "| 1        | 0.96      | 0.96   | 0.96     | 2950    |\n",
        "| Accuracy |           |        | 0.96     | 5666    |\n",
        "\n",
        "* **Macro Avg (no ponderado)**: Todas las mÃ©tricas promedian 0.96, lo que indica un desempeÃ±o parejo entre clases.\n",
        "* **Weighted Avg (ponderado)**: Igualmente 0.96, confirmando que el modelo mantiene alta precisiÃ³n incluso considerando la proporciÃ³n de cada clase.\n",
        "\n",
        "ðŸ”¹InterpretaciÃ³n\n",
        "\n",
        "* **Rendimiento equilibrado**: El modelo clasifica con la misma eficacia ambas clases, lo que es ideal para tareas donde ambas categorÃ­as tienen valor estratÃ©gico.\n",
        "* *No se requieren ajustes adicionalesÂ¨**: Dado el balance en el desempeÃ±o y la distribuciÃ³n relativamente pareja del soporte entre clases, no se observan problemas de desbalance ni necesidad de tÃ©cnicas de reponderaciÃ³n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "dSpDWvqtoO5B",
        "outputId": "3722b763-7395-407b-cddc-079b45b5fe7a"
      },
      "outputs": [],
      "source": [
        "# Generar matriz de confusiÃ³n\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualizar la matriz de confusiÃ³n\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel(\"PredicciÃ³n\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de ConfusiÃ³n\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc0iZw3so2Qu"
      },
      "source": [
        "ðŸ”¹AnÃ¡lisis de la Matriz de ConfusiÃ³n\n",
        "\n",
        "|        | Predicho 0 | Predicho 1 |\n",
        "| ------ | ---------- | ---------- |\n",
        "| Real 0 | 2608 (VN)  | 108 (FP)   |\n",
        "| Real 1 | 119 (FN)   | 2831 (VP)  |\n",
        "\n",
        "InterpretaciÃ³n\n",
        "\n",
        "* **PrecisiÃ³n elevada en ambas clases**: El modelo clasifica correctamente el 96% de los casos de cada clase, con un buen balance entre Verdaderos Positivos (2831) y Verdaderos Negativos (2608).\n",
        "\n",
        "* **Errores moderados**:\n",
        "  * **Falsos Positivos (108)**: Casos de clase 0 incorrectamente clasificados como 1.\n",
        "  * **Falsos Negativos (119)**: Casos de clase 1 predichos como 0.\n",
        "  * Estos errores son proporcionales y no generan sesgo significativo en el modelo.\n",
        "* **Balance de clases**: No se observa una desproporciÃ³n crÃ­tica entre clases (2716 vs. 2950), por lo que no es estrictamente necesario aplicar tÃ©cnicas de balanceo (como resampling o class weighting). Sin embargo, podrÃ­an explorarse en una etapa de refinamiento para optimizar la sensibilidad o reducir falsos negativos, dependiendo del costo de error para el negocio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConclusiÃ³n Final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este proyecto demostrÃ³ un enfoque completo y estructurado para el anÃ¡lisis y modelado de datos reales del sector financiero. A travÃ©s de un proceso de limpieza, transformaciÃ³n y evaluaciÃ³n de mÃºltiples modelos, se lograron los siguientes resultados clave:\n",
        "\n",
        "* **Calidad del dataset**: Se logrÃ³ una base de datos limpia, sin valores nulos, con variables transformadas adecuadamente y codificadas para el modelado.\n",
        "* **AnÃ¡lisis exploratorio**: IdentificÃ³ patrones relevantes, como la alta concentraciÃ³n de clientes en ciertos segmentos (RegiÃ³n 13, subsegmento 170), y un uso predominantemente bajo de productos financieros.\n",
        "* **Modelado de regresiÃ³n**: El modelo de regresiÃ³n lineal aplicado al target transformado (log(1 + transacciones anuales)) logrÃ³ un desempeÃ±o aceptable (MSE: 0.31, RMSE: 0.55), aunque se reconociÃ³ que no era ideal para producciÃ³n.\n",
        "* **Modelado de clasificaciÃ³n**: Se desarrollÃ³ un modelo robusto de clasificaciÃ³n binaria para la retenciÃ³n de clientes, alcanzando una exactitud del 96%, sin seÃ±ales de overfitting ni underfitting. La matriz de confusiÃ³n y mÃ©tricas como precisiÃ³n, recall y F1-score confirmaron un desempeÃ±o equilibrado entre clases."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
